{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd9c638-9ffa-4fb5-9d65-399d787d18da",
   "metadata": {},
   "source": [
    "# Manifesto data retrieval\n",
    "For US, Japan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db3299-43ae-4a8b-be7e-d90dcca9f171",
   "metadata": {},
   "source": [
    "## Download Manifesto Data\n",
    "- https://manifesto-project.wzb.eu/information/documents/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db90864b-5c7f-4c51-87e2-b8842efd4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.data.download_manifesto import DownloadManifesto\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "dataset_key = \"MPDS2024a\"\n",
    "version = '2024-1'\n",
    "api_key = os.getenv(\"MANIFESTO_API\")\n",
    "downloader =  DownloadManifesto(dataset_key, version, api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a577517-1918-4d42-a807-09d70d71545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['United States', 'Japan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f6b11-a429-4ebb-85e0-9d95e621c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "df_all_countries = []\n",
    "for country in tqdm(countries):\n",
    "    print(country)\n",
    "    result = downloader.get_country_data(country)\n",
    "    df, metadata = downloader.get_metadata(result)\n",
    "    df_country = downloader.get_texts(df)  # Get texts\n",
    "    df_all_countries.append(df_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa0c2a2-08a4-4b5a-918b-d9eff00cbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(df_all_countries, axis='rows')\n",
    "df_all = df_all.rename(lambda x: pd.to_datetime(x, format = \"%Y%m\"), axis=0, level=1) # convert date to date time\n",
    "df_all = df_all.reset_index()\n",
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e8c63-b3fb-4b29-b377-57ccb30ab555",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"../data/processed/manifesto_us_japan.parquet\"\n",
    "df_all.to_parquet(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a1b43",
   "metadata": {},
   "source": [
    "## Import generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb47bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_parquet(\"../data/processed/manifesto_us_japan.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559962ab",
   "metadata": {},
   "source": [
    "## To do: Translate Japanese manifesto into English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92445e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32    安倍政権の暴走ストップ！ 国民の声が生きる新しい政治を 日本共産党の総選挙政策 日本共産党 ...\n",
       "33    約束１　アベノミクスによる生活破壊を許さず、拡大した格差を是正します （１）景気を悪化させる...\n",
       "34    日本共産党の総選挙政策 日本共産党 安倍首相は、臨時国会の冒頭解散に打って出ました。 「森友...\n",
       "35    くらし支えます 1家計を温めボトムアップの経済政策でくらしの再建 憲法１３条の幸福追求権、２...\n",
       "36    消費増税凍結! 維新ならできる! 増税なしで改革実現! 身を切る改革で財源を生み出し、議員報...\n",
       "37    1 生活の現場から暮らしを立て直します アベノミクスの成果は上がらず、国民の所得を削り、中間...\n",
       "38    教育負担の軽減へ。 衆院選で公明党は、「教育負担の軽減へ。」を掲げます。 国づくりの基...\n",
       "39    北朝鮮の脅威から、 国民を守り抜きます わが国の上空を飛び越える弾道ミサイルの相次ぐ発...\n",
       "40    私たちが希求するものは、党の利益ではなく、議員の利益でもなく、 国民のため、つまり国民...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[df_all[\"countryname\"] == \"Japan\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8ba1a",
   "metadata": {},
   "source": [
    "## Need to fix this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5768aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Translation of Japanese text to English using a pre-trained model\n",
    "import transformers\n",
    "from transformers import EncoderDecoderModel\n",
    "import torch\n",
    "\n",
    "encoder_model_name = \"cl-tohoku/bert-base-japanese-v2\"\n",
    "decoder_model_name = \"openai-community/gpt2\"\n",
    "src_tokenizer = transformers.BertJapaneseTokenizer.from_pretrained(encoder_model_name)\n",
    "trg_tokenizer = transformers.PreTrainedTokenizerFast.from_pretrained(decoder_model_name)\n",
    "\n",
    "EncoderDecoderModel.from_pretrained(\n",
    "    \"sappho192/jesc-ja-en-translator\").save_pretrained(\"../src/model/jesc-ja-en-translator\")\n",
    "model = EncoderDecoderModel.from_pretrained(\"../src/model/jesc-ja-en-translator\").to(\"cpu\")\n",
    "\n",
    "MAX_TOKENS = 480\n",
    "\n",
    "def chunk_text(text, tokenizer, max_tokens):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    chunks = []\n",
    "    for i in range(0, len(tokens), max_tokens):\n",
    "        chunk = tokens[i:i + max_tokens]\n",
    "        chunk_text = tokenizer.convert_tokens_to_string(chunk)\n",
    "        chunks.append(chunk_text)\n",
    "    return chunks\n",
    "\n",
    "def translate(text_src):\n",
    "    chunks = chunk_text(text_src, src_tokenizer, MAX_TOKENS)\n",
    "    translated_chunks = []\n",
    "    for chunk in chunks:\n",
    "        embeddings = src_tokenizer(chunk, return_attention_mask=False, return_token_type_ids=False, return_tensors='pt')\n",
    "        output = model.generate(**embeddings, max_length=512)[0, 1:-1]\n",
    "        text_trg = trg_tokenizer.decode(output.cpu(), skip_special_tokens=True)\n",
    "        translated_chunks.append(text_trg)\n",
    "    return \" \".join(translated_chunks)\n",
    "\n",
    "# Only Japan data will be processed\n",
    "tqdm.pandas()\n",
    "df_all.loc[df_all[\"countryname\"] == \"Japan\", \"text_eng\"] = \\\n",
    "    df_all.loc[df_all[\"countryname\"] == \"Japan\", \"text\"].progress_apply(translate)\n",
    "\n",
    "df_all.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efbbe8-af98-48d4-9d8c-921504175117",
   "metadata": {},
   "source": [
    "## Count words across time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9afea11-2a38-409e-9644-97e80d742c45",
   "metadata": {},
   "source": [
    "### Count by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079db915-6d63-4471-ad07-99e38004c034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ghg': 0, 'greenhouse': 23, 'net-zero': 0, 'carbon': 42}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab_list = ['ghg', 'greenhouse', 'net-zero', 'carbon']\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words = 'english',     # Remove stop words. Can be a list of stop words or a string from {'english', 'spanish'}.\n",
    "    lowercase = True,           # Convert text to lowercase.\n",
    "    ngram_range = (1,1),\n",
    "    vocabulary = vocab_list\n",
    "\n",
    ")\n",
    "counts = vectorizer.fit_transform(df_all['text']).toarray().sum(axis=0)\n",
    "word_freq = dict(zip(vectorizer.get_feature_names_out(), counts))\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de453867-1c3e-4247-90cc-fd7474dd789a",
   "metadata": {},
   "source": [
    "### Count by year and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bd49c97-96db-4adc-b040-afa14872dc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>countryname</th>\n",
       "      <th>date</th>\n",
       "      <th>party</th>\n",
       "      <th>partyname</th>\n",
       "      <th>keys</th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>1960-11-01</td>\n",
       "      <td>61320</td>\n",
       "      <td>Democratic Party</td>\n",
       "      <td>61320_196011</td>\n",
       "      <td>61320_196011</td>\n",
       "      <td>In 1796, in America's first contested national...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1960-11-01</td>\n",
       "      <td>61620</td>\n",
       "      <td>Republican Party</td>\n",
       "      <td>61620_196011</td>\n",
       "      <td>61620_196011</td>\n",
       "      <td>PREAMBLE The United States is living in an age...</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    countryname       date  party         partyname          keys  \\\n",
       "0      0  United States 1960-11-01  61320  Democratic Party  61320_196011   \n",
       "1      1  United States 1960-11-01  61620  Republican Party  61620_196011   \n",
       "\n",
       "   manifesto_id                                               text  year  \n",
       "0  61320_196011  In 1796, in America's first contested national...  1960  \n",
       "1  61620_196011  PREAMBLE The United States is living in an age...  1960  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add year column\n",
    "df_all = df_all.reset_index().assign(year = lambda column: column['date'].dt.year)\n",
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d307580-8bb0-4485-a7f9-ab3d6492a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ghg</th>\n",
       "      <th>greenhouse</th>\n",
       "      <th>net-zero</th>\n",
       "      <th>carbon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Japan</th>\n",
       "      <th>2014</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">United States</th>\n",
       "      <th>1960</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ghg  greenhouse  net-zero  carbon\n",
       "Japan         2014    0           0         0       0\n",
       "              2017    0           0         0       0\n",
       "United States 1960    0           0         0       0\n",
       "              1964    0           0         0       0\n",
       "              1968    0           0         0       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq_by_country = {}\n",
    "for country_name, country_df in df_all.groupby(['countryname', 'year']):\n",
    "    vectorizer = CountVectorizer(\n",
    "        stop_words='english',\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 1),\n",
    "        vocabulary=vocab_list\n",
    "    )\n",
    "    counts = vectorizer.fit_transform(country_df['text']).toarray().sum(axis=0)\n",
    "    word_freq_by_country[country_name] = dict(zip(vectorizer.get_feature_names_out(), counts))\n",
    "df_timeseries = pd.DataFrame(word_freq_by_country).transpose()\n",
    "df_timeseries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "175676a0-feed-42a4-9734-3234d5d4c791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>level_2</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>2014</td>\n",
       "      <td>ghg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>2014</td>\n",
       "      <td>greenhouse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Japan</td>\n",
       "      <td>2014</td>\n",
       "      <td>net-zero</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  level_0  level_1     level_2  count\n",
       "0   Japan     2014         ghg      0\n",
       "1   Japan     2014  greenhouse      0\n",
       "2   Japan     2014    net-zero      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df_timeseries.stack().to_frame('count').reset_index()\n",
    "df_long.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029c27eb-ba25-4ded-9952-a1895004f932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>vocab</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Japan</td>\n",
       "      <td>2014</td>\n",
       "      <td>ghg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Japan</td>\n",
       "      <td>2014</td>\n",
       "      <td>greenhouse</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year       vocab  count\n",
       "0   Japan  2014         ghg      0\n",
       "1   Japan  2014  greenhouse      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = df_long.rename({\"level_0\": 'country', 'level_1':'year', 'level_2': 'vocab'}, axis='columns')\n",
    "df_long.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fde051-b880-4962-bcca-c135b49d590c",
   "metadata": {},
   "source": [
    "#### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f140e7f9-2bed-4948-baf2-9bc623db814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.to_csv(\"../data/processed/manifesto_us_japan_word_freq.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59650112-00d9-492b-a2e5-77e5bd7354c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
