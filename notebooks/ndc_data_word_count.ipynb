{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "275d3ff8",
   "metadata": {},
   "source": [
    "# NDC data processing and word counting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8bb5b",
   "metadata": {},
   "source": [
    "## Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7fe1bbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU2023</td>\n",
       "      <td>../data/raw/ES-2023-10-17 EU submission NDC up...</td>\n",
       "      <td>1  Update of the NDC of the European  Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU2023</td>\n",
       "      <td>../data/raw/ES-2023-10-17 EU submission NDC up...</td>\n",
       "      <td>2  Update of the NDC of the European  Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EU2023</td>\n",
       "      <td>../data/raw/ES-2023-10-17 EU submission NDC up...</td>\n",
       "      <td>3  Update of the NDC of the European  Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EU2023</td>\n",
       "      <td>../data/raw/ES-2023-10-17 EU submission NDC up...</td>\n",
       "      <td>4  Update of the NDC of the European  Unio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU2023</td>\n",
       "      <td>../data/raw/ES-2023-10-17 EU submission NDC up...</td>\n",
       "      <td>5  Update of the NDC of the European  Unio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country                                             source  \\\n",
       "0  EU2023  ../data/raw/ES-2023-10-17 EU submission NDC up...   \n",
       "1  EU2023  ../data/raw/ES-2023-10-17 EU submission NDC up...   \n",
       "2  EU2023  ../data/raw/ES-2023-10-17 EU submission NDC up...   \n",
       "3  EU2023  ../data/raw/ES-2023-10-17 EU submission NDC up...   \n",
       "4  EU2023  ../data/raw/ES-2023-10-17 EU submission NDC up...   \n",
       "\n",
       "                                                text  \n",
       "0      1  Update of the NDC of the European  Unio...  \n",
       "1      2  Update of the NDC of the European  Unio...  \n",
       "2      3  Update of the NDC of the European  Unio...  \n",
       "3      4  Update of the NDC of the European  Unio...  \n",
       "4      5  Update of the NDC of the European  Unio...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "pdf_path = {\"EU2023\": \"../data/raw/ES-2023-10-17 EU submission NDC update.pdf\",\n",
    "            \"US2021\": \"../data/raw/United States NDC April 21 2021 Final.pdf\",\n",
    "            \"US2024\": \"../data/raw/United States 2035 NDC.pdf\"}\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for key, path in pdf_path.items():\n",
    "    with open(path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text_list = [page.extract_text().replace('\\n', '') \\\n",
    "                    if page.extract_text() else '' for page in reader.pages]\n",
    "    df = pd.DataFrame({'country': key,\n",
    "                       'source': path,\n",
    "                       'text': text_list})\n",
    "    dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40565f4d",
   "metadata": {},
   "source": [
    "## Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c8a307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ghg</th>\n",
       "      <th>greenhouse</th>\n",
       "      <th>net-zero</th>\n",
       "      <th>carbon</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>US2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>US2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ghg  greenhouse  net-zero  carbon country\n",
       "0    7          29         0      21  EU2023\n",
       "1    1          43         0      36  US2021\n",
       "2    3          58         0      33  US2024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vocab_list = ['ghg', 'greenhouse', 'net-zero', 'carbon']\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words='english',     # Remove stop words. Can be a list of stop words or a string from {'english', 'spanish'}.\n",
    "    lowercase=True,           # Convert text to lowercase.\n",
    "    ngram_range=(1, 1),\n",
    "    vocabulary=vocab_list\n",
    ")\n",
    "\n",
    "dfs_count = []\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    counts = vectorizer.fit_transform(df.loc[df[\"country\"] == country, 'text']).toarray().sum(axis=0)\n",
    "    word_freq = dict(zip(vectorizer.get_feature_names_out(), counts))\n",
    "    row = word_freq.copy()\n",
    "    row['country'] = country\n",
    "    df_count = pd.DataFrame([row])\n",
    "    dfs_count.append(df_count)\n",
    "\n",
    "df_count = pd.concat(dfs_count, ignore_index=True)\n",
    "df_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078444c",
   "metadata": {},
   "source": [
    "## Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffdfe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count.to_csv('../data/processed/ndc_word_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad4085",
   "metadata": {},
   "source": [
    "# Use LLM to extract words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb6aea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = InferenceClient(\n",
    "    provider=\"together\",\n",
    "    api_key=os.getenv(\"HF_API\")\n",
    ")\n",
    "\n",
    "def extract_climate_words(text):\n",
    "    # This function will be used to extract climate-related words and their context.\n",
    "    # The implementation will depend on the model's capabilities.\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please extract climate change related words and count by word and return as a Python dict.\\\n",
    "            Please return only the dict, no other text. Target sentence:\" + text\n",
    "        }\n",
    "    ],\n",
    "    )\n",
    "    return ast.literal_eval(completion.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e183a2c",
   "metadata": {},
   "source": [
    "### Data is ignored when LLM word counting is failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d724c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>0</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>climate change</td>\n",
       "      <td>4</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Paris Agreement</td>\n",
       "      <td>16</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>COP</td>\n",
       "      <td>2</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Lima</td>\n",
       "      <td>1</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>EU2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0          level_1   0 country\n",
       "0        0   climate change   4  EU2023\n",
       "1        0  Paris Agreement  16  EU2023\n",
       "2        0              COP   2  EU2023\n",
       "3        0             Lima   1  EU2023\n",
       "4        0             2015   1  EU2023"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "\n",
    "for country in df['country'].unique():\n",
    "    dicts = []\n",
    "    for text in df.loc[df[\"country\"] == country, 'text']:\n",
    "        climate_words = extract_climate_words(text)\n",
    "        dicts.append(climate_words)\n",
    "    revised_dicts = []\n",
    "\n",
    "    for dic in dicts:\n",
    "        revised_dicts.append(dic.replace('\",', '\":').replace('\"}', '\": 1}'))\n",
    "\n",
    "    merged_dict = ast.literal_eval(revised_dicts[0])\n",
    "    for dic in revised_dicts[1:]:\n",
    "        try:\n",
    "            eval_dict = ast.literal_eval(dic)\n",
    "        except:\n",
    "            continue\n",
    "        for key, value in eval_dict.items():\n",
    "            merged_dict[key] = merged_dict.get(key, 0) + value\n",
    "\n",
    "    df_count = pd.DataFrame(merged_dict, index=[0])\n",
    "    df_count = df_count.stack().reset_index()\n",
    "    df_count['country'] = country\n",
    "    dfs.append(df_count)\n",
    "\n",
    "df_climate = pd.concat(dfs, ignore_index=True)\n",
    "df_climate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "33f7a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate.drop(columns=['level_0'], inplace=True)\n",
    "df_climate.columns = ['word', 'count', 'country']\n",
    "df_climate.to_csv('../data/processed/ndc_climate_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce71d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
